whisper_init_from_file_with_params_no_state: loading model from '/root/madcamp04/FSD/models/ggml-large-v3.bin'
whisper_init_with_params_no_state: use gpu    = 1
whisper_init_with_params_no_state: flash attn = 1
whisper_init_with_params_no_state: gpu_device = 0
whisper_init_with_params_no_state: dtw        = 0
ggml_cuda_init: found 1 CUDA devices:
  Device 0: NVIDIA GeForce RTX 3090, compute capability 8.6, VMM: yes
whisper_init_with_params_no_state: devices    = 2
whisper_init_with_params_no_state: backends   = 2
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51866
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 1280
whisper_model_load: n_audio_head  = 20
whisper_model_load: n_audio_layer = 32
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 1280
whisper_model_load: n_text_head   = 20
whisper_model_load: n_text_layer  = 32
whisper_model_load: n_mels        = 128
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 5 (large v3)
whisper_model_load: adding 1609 extra tokens
whisper_model_load: n_langs       = 100
whisper_model_load:        CUDA0 total size =  3094.36 MB
whisper_model_load: model size    = 3094.36 MB
whisper_backend_init_gpu: device 0: CUDA0 (type: 1)
whisper_backend_init_gpu: found GPU device 0: CUDA0 (type: 1, cnt: 0)
whisper_backend_init_gpu: using CUDA0 backend
whisper_init_state: kv self size  =   83.89 MB
whisper_init_state: kv cross size =  251.66 MB
whisper_init_state: kv pad  size  =    7.86 MB
whisper_init_state: compute buffer (conv)   =   37.69 MB
whisper_init_state: compute buffer (encode) =   55.35 MB
whisper_init_state: compute buffer (cross)  =    9.27 MB
whisper_init_state: compute buffer (decode) =  100.04 MB

system_info: n_threads = 4 / 40 | WHISPER : COREML = 0 | OPENVINO = 0 | CUDA : ARCHS = 750,800,860,890,900,1000,1030,1100,1200,1210 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | OPENMP = 1 | REPACK = 1 | 

operator(): processing 'audio.wav' (40000 samples, 2.5 sec), 4 threads, 1 processors, lang = ko, task = transcribe, timestamps = 1 ...


system_info: n_threads = 4 / 40 | WHISPER : COREML = 0 | OPENVINO = 0 | CUDA : ARCHS = 750,800,860,890,900,1000,1030,1100,1200,1210 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | OPENMP = 1 | REPACK = 1 | 

operator(): processing 'audio.wav' (46720 samples, 2.9 sec), 4 threads, 1 processors, lang = ko, task = transcribe, timestamps = 1 ...


system_info: n_threads = 4 / 40 | WHISPER : COREML = 0 | OPENVINO = 0 | CUDA : ARCHS = 750,800,860,890,900,1000,1030,1100,1200,1210 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | OPENMP = 1 | REPACK = 1 | 

operator(): processing 'audio.wav' (128000 samples, 8.0 sec), 4 threads, 1 processors, lang = ko, task = transcribe, timestamps = 1 ...


system_info: n_threads = 4 / 40 | WHISPER : COREML = 0 | OPENVINO = 0 | CUDA : ARCHS = 750,800,860,890,900,1000,1030,1100,1200,1210 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | AVX512 = 1 | AVX512_VNNI = 1 | OPENMP = 1 | REPACK = 1 | 

operator(): processing 'audio.wav' (69440 samples, 4.3 sec), 4 threads, 1 processors, lang = ko, task = transcribe, timestamps = 1 ...


whisper_print_timings:     load time =  1548.58 ms
whisper_print_timings:     fallbacks =   1 p /   0 h
whisper_print_timings:      mel time =    91.19 ms
whisper_print_timings:   sample time =    80.22 ms /     1 runs (    80.22 ms per run)
whisper_print_timings:   encode time =   354.63 ms /     4 runs (    88.66 ms per run)
whisper_print_timings:   decode time =   564.26 ms /    91 runs (     6.20 ms per run)
whisper_print_timings:   batchd time =   110.67 ms /    33 runs (     3.35 ms per run)
whisper_print_timings:   prompt time =     0.00 ms /     1 runs (     0.00 ms per run)
whisper_print_timings:    total time = 157444.84 ms

whisper server listening at http://0.0.0.0:8081

Received request: audio.wav
Successfully loaded audio.wav
Running whisper.cpp inference on audio.wav
Received request: audio.wav
Successfully loaded audio.wav
Running whisper.cpp inference on audio.wav
Received request: audio.wav
Successfully loaded audio.wav
Running whisper.cpp inference on audio.wav
Received request: audio.wav
Successfully loaded audio.wav
Running whisper.cpp inference on audio.wav

Caught signal 15, shutting down gracefully...
